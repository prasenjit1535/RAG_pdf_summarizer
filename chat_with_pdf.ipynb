{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiQ3i5iC5C1a"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_groq import ChatGroq\n",
        "from base64 import b64decode\n",
        "import os\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.documents import Document\n",
        "from base64 import b64decode\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your Groq API key\n",
        "#os.environ[\"GROQ_API_KEY\"] = \"your-api-key-here\"  # Replace with your actual key\n",
        "\n",
        "# Document parser with error handling\n",
        "def parse_docs(docs):\n",
        "    \"\"\"Extract text and base64 images from documents\"\"\"\n",
        "    b64_images = []\n",
        "    text_chunks = []\n",
        "\n",
        "    for doc in docs:\n",
        "        # Handle different document formats\n",
        "        if isinstance(doc, Document):\n",
        "            content = doc.page_content\n",
        "        else:\n",
        "            content = str(doc)\n",
        "\n",
        "        # Validate base64 images\n",
        "        try:\n",
        "            if content.startswith(\"data:image/\"):\n",
        "                b64decode(content.split(\",\")[1])\n",
        "                b64_images.append(content)\n",
        "                continue\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        text_chunks.append(content)\n",
        "\n",
        "    return {\"images\": b64_images, \"texts\": text_chunks}\n",
        "\n",
        "# Prompt builder with validation\n",
        "def build_prompt(inputs):\n",
        "    \"\"\"Construct LLM prompt from context and question\"\"\"\n",
        "    if not isinstance(inputs, dict) or \"context\" not in inputs:\n",
        "        raise ValueError(\"Invalid input format for prompt building\")\n",
        "\n",
        "    context_text = \"\\n\".join(inputs[\"context\"][\"texts\"])\n",
        "    question = inputs[\"question\"]\n",
        "\n",
        "\n",
        "\n",
        "    ''' if len(docs_by_type[\"images\"]) > 0:\n",
        "        for image in docs_by_type[\"images\"]:\n",
        "            prompt_content.append(\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "                }\n",
        "            )'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return f\"\"\"You are an expert literary analyst. Answer the question using only the provided context.\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer in complete sentences, being careful to:\n",
        "- Do not start with based on the provided context\n",
        "- Cite specific details from the context\n",
        "- do not assume anything about the context\n",
        "- If unsure, state that information is not available\n",
        "- Format your response clearly with proper paragraph breaks\"\"\"\n",
        "\n",
        "# Robust chain construction\n",
        "chain = (\n",
        "    {\n",
        "        \"context\": RunnableLambda(parse_docs),  # Directly process retriever output\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | RunnableLambda(build_prompt)\n",
        "    | ChatGroq(\n",
        "        model_name=\"llama3-70b-8192\",  # More capable than 8B model\n",
        "        temperature=0.2,               # More factual responses\n",
        "        max_tokens=1024,\n",
        "        max_retries=3,                # Built-in retry mechanism\n",
        "    )\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Retry decorator for API calls\n",
        "@retry(\n",
        "    stop=stop_after_attempt(3),\n",
        "    wait=wait_exponential(multiplier=1, min=2, max=30),\n",
        "    reraise=True\n",
        ")\n",
        "def get_answer(question):\n",
        "    \"\"\"Safe execution with error handling\"\"\"\n",
        "    try:\n",
        "        return chain.invoke(question)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing question: {str(e)}\")\n",
        "        raise\n",
        "\n"
      ],
      "metadata": {
        "id": "OsbVk6am5gK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"The Ministry of Industry and Information Technology (MIIT) is responsible for?\"\n",
        "response = get_answer(question)\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "QT4DyqKr5kBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question=\"Chinas ICT system consists of?\"\n",
        "response = get_answer(question)\n",
        "print(\"\\nFinal Answer:\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "GRnelAPr5j9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdrX2nGO5neh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}